Название статьи,Ссылка на текст,LLM,Среда/датасет,Как представляется план,Метрики качества,Тип обратной связи,Какие проблемы решаются/ вклад статьи,Основные особенности,Комментарии,Ссылка на код и/или блог
"Language Models as Zero-Shot Planners:
Extracting Actionable Knowledge for Embodied Agents",*2201.07207.pdf (arxiv.org),GPT3-175B с дополнительными улучшениями(надстройками),VirtualHome/ActivityPrograms,"Пример:
Task: Take jacket off
Step 1: Walk to home office
Step 2: Walk to jacket
Step 3: Find jacket
Step 4: Grab jacket
Step 5: Find chair
Step 6: Sit on chair
Step 7: Take jacket off","Executability, correctness",,"Рассматривается новый подход к использованию LLM, основной тезис в том, что LLM уже содержит необходимое знание для выполнения задачи планирования
Решаются проблемы семантического понимания и планирования действий в контексте виртуальных сред
Более подробно:      
1.Свободноформатный текст планов не всегда может быть преобразован в явные, понятные для робота действия.
2.Авторегрессионная корректировка траектории
3.Выбор релевантного аннотированного плана",,"Есть преположение, один из черновых вариантов начать делать валидацию плана -  использовать метод авторегрессионного корректирования траектории(плана), можно взять это как нулевой вариант",https://github.com/huangwl18/language-planner
PROGPROMPT: Generating Situated Robot Task Plans using Large Language Models,2209.11302.pdf (arxiv.org),"CODEX(показала лучшие результаты SR 0.40±0.11, GCR 0.90±0.05 и Exec 0.72±0.09)",VirtualHome,"План генерится в таком виде:
grab and putin(obj1, obj2)(берется синтаксис питона)","Success Rate (SR), Goal Conditions Recall (GCR) и Executability (Exec)",Обратная связь происходит за счет assert которые помещаются в структуре программы,"Решается проблема автоматизированного планирования действий для роботов в разнообразных сценариях, предлагается метод, который интегрирует ситуативное понимание в языковые модели, используя формальные языки(python). Ключевой вклад заключается в том, что метод способен генерировать ситуированные планы задач, учитывая контекст среды, что ранее было проблематично для языковых моделей. ",,"На самом деле, есть идея, использовать assert в структуре запроса, который заставляет триггернуться например функцию которая заставляет модель перегенерировать('перепроверить') ту часть плана, которая заставила триггернуться assert .Но соответственно, до исполнения плана должна ""скомпелироваться"" промпт-запрос который написан в форме программы.Возможно, если выход с LLM, к который был дан запрос в формате PROGPROMPT, имеет структуру кода,то этот план мы подаем в функцию-компилятор, которая просто пробегает по плану
(может звучать как бред)", 
"Code as Policies: Language Model Programs for Embodied Control
",arxiv.org/pdf/2209.07753.pdf,"OpenAI Codex code-davinci-002 with
temperature 0","RoboCodeGen (с вопросами о пространственном мышлении, геометрии и управлении) и HumanEval (стандартные проблемы генерации кода)","Инструкции роботу генерируется в виде программного кода, того же Python, только уже разный уровень абстракций и глубина",,,"LLM и LMP используют как генератотр для создания высокоуровневого программного кода робота на основе естественноязыковых команд.

что решается?
Генерация кода из естественного языка: 
Идея использовать LLM, обученные на коде, для того чтобы автоматически создавать программный код робота на основе естественноязыковых команд.

Использование комментариев в коде: 
также предлагают форматировать естественноязыковые команды как комментарии в коде, что обеспечивает примеры для обучения LLM и позволяет ему генерировать соответствующий программный код.

Иерархическая генерация кода: 
Метод иерархической генерации кода представляет собой важный вклад, позволяя LLM создавать более сложные программы, включая рекурсивное определение новых функций.",,"Предоставление задачи:

Пользователь предоставляет естественноязыковые инструкции для выполнения задачи роботом.
Генерация плана с использованием LMP (Language Model for Planning):

Модель LMP (возможно, использующая GPT-4) использует предоставленные инструкции для генерации последовательности действий на языке программирования (например, PDDL).
Проверка соответствия плана условиям среды:

Модель EnvironmentVerifier проверяет, соответствует ли сгенерированный план условиям среды.
Утверждения (assertions) в коде плана используются для проверки предварительных условий перед выполнением каждого действия.
В случае несоответствия, переход к следующему шагу.
Авторегрессивная коррекция плана:

Для каждого действия, не соответствующего условиям среды, используется алгоритм TrajectoryCorrector для автоматической коррекции траектории.
Запрос к Planning LM (Language Model) для генерации нескольких вариантов для каждого действия (k samples).
Выбор наилучшего действия осуществляется на основе семантической корректности и его достижимости в среде.
Корректированные действия добавляются в пересчитанный план.
Процесс повторяется для каждого действия, не соответствующего условиям среды.
Повторная проверка плана после коррекции:

Корректированный план повторно проверяется с использованием модели EnvironmentVerifier для окончательного подтверждения соответствия условиям среды.",https://github.com/google-research/google-research/tree/master/code_as_policies
"ChatGPT for Robotics: Design Principles and Model Abilities
",2306.17582.pdf (arxiv.org),ChatGPT,,,,,"Представлен обширный обзор экспериментов по использованию ChatGPT в контексте решения разнообразных задач в области робототехники.
Универсальность и нулевой шаг планирования задач: ChatGPT проявляет способность решать задачи робототехники без предоставления конкретных примеров кода, что позволяет обобщать на новые сценарии.
Способность к пространственно-временному рассуждению: Модель успешно справляется с задачами, требующими понимания пространственно-временных взаимосвязей, например, в задаче перехвата мяча.
Перевод нечетких инструкций в команды для робота: ChatGPT может создавать код для управления беспилотными агентами, используя естественный язык и нечеткие инструкции, обеспечивая эффективное взаимодействие с человеком.
Замкнутые циклы восприятия и действия: Модель демонстрирует способность создавать код для замкнутых циклов, используя визуальные данные и API-библиотеку для управления роботом.
Логическое мышление и задачи общего смысла: ChatGPT успешно решает логические задачи и базовые задачи робототехники, что делает его отличным стартовым пунктом для разработки более сложных систем робототехники.",,"Статья больше обзорная, представляются возможности ChatGPT. Хорошим вкладом для валидации плана является то, что в статье упоминается, что PromptCraft предоставляет среду AirSim с оберткой ChatGPT для исследования стратегий планирования, возможно для финальных тестов способов валидации плана пригодятся эти среды",GitHub - microsoft/PromptCraft-Robotics: Community for applying LLMs to robotics and a robot simulator with ChatGPT integration
"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency
",https://arxiv.org/pdf/2304.11477.pdf, GPT4,"Для проведения экспериментов был использован набор данных, состоящий из семи доменов планирования, заимствованных из предыдущих международных соревнований по планированию. Каждый домен содержит 20 автоматически сгенерированных задач. Вот некоторые из доменов:

BLOCKSWORLD: Задача по перемещению блоков для достижения целевой конфигурации.

BARMAN: Задача для робота-бармена, который создает коктейли по заказу.

FLOORTILE: Роботы должны использовать цветные узоры для раскрашивания плиток на полу, следуя правилам движения.

GRIPPERS: Роботы с двумя схватами перемещают объекты между разными комнатами.

STORAGE: Задача подъема и опускания ящиков с использованием лебедок в разных хранилищах.

TERMES: Робот строит сложные структуры, перенося и устанавливая блоки.

TYREWORLD: Робот заменяет плоские шины, выполняя различные действия в правильном порядке.",PDDL,Success Rate,,"Основной вклад статьи заключается в представлении методологии под названием LLM+P (Large Language Model + Planning), которая позволяет использовать большие языковые модели(GPT-4), для решения задач планирования. Основные особенности и этапы методологии включают:

Формулирование проблемы в PDDL: LLM+P позволяет использовать LLM для перевода естественного языка, описывающего проблему, в язык PDDL (Planning Domain Definition Language), который является стандартизированным языком представления классических задач планирования.

Решение задачи с использованием общего планировщика: Получив PDDL-представление задачи, LLM+P применяет общий планировщик для генерации оптимального плана для решения поставленной проблемы. Общие планировщики обеспечивают логическую корректность и, при наличии, находят оптимальные планы.

Перевод результата обратно в естественный язык: Сгенерированный план, представленный в PDDL, в конечном итоге переводится обратно в естественный язык с использованием LLM. Это позволяет предоставить пользователю понятное и человекочитаемое описание решения.",,Использование PDDL в основе верификации плана будет скорее всего являться лучшим решением,
"Generalized Planning in PDDL Domains with Pretrained Large Language Models
",https://arxiv.org/pdf/2305.11014.pdf, GPT4,"Взяли домены PDDL(Delivery, Forest,Gripper,Miconic,Ferry,Spanner,Heavy)",Python code,,,"алгоритм, названный PG3 (Probabilistic Generalization 3), представляет собой метод обобщенного планирования в PDDL-доменах с использованием предварительно обученных LLMs, таких как GPT-4. Основной вопрос, который исследуется этим алгоритмом, - возможность использования LLMs для синтеза программ, способных генерировать действительные планы для различных задач в заданном PDDL-домене.

Основные шаги алгоритма:
Подготовка данных:

PDDL Домены и Задачи: Определение полностью наблюдаемых задач планирования в PDDL, включая имена, типы, предикаты и операторы.
Обучающие и Оценочные Задачи: Выбор набора обучающих задач для создания программы и оценочных задач для измерения производительности.

Подход к LLMs
Протокол Запросов (Prompting Protocol): Разработка протокола взаимодействия с LLMs. В данном случае используется протокол Chain-of-Thought (CoT), включающий три этапа: суммаризация домена, предложение стратегии и реализация стратегии в виде программы на Python.

Автоматизированное Интерактивное Отладочное взаимодействие:
Проверка программ: После синтеза программы LLM на каждом этапе, происходит проверка программы на обучающих задачах. Если программа успешно решает задачу, то переход к следующей задаче, иначе происходит взаимодействие с LLM для выявления и исправления ошибок.",,,
Text2Motion: From Natural Language Instructions to Feasible Plans,https://arxiv.org/pdf/2303.12153.pdf,STAP(https://arxiv.org/pdf/2210.12250.pdf),,"План представляется в виде предикатов, которые затем передаются в функцию для физического манипулятора","Success Rate, Subgoal Completion Rate",Feasibility Check,"
Методология, предложенная в данной статье, направлена на обеспечение геометрической выполнимости плана задачи, разработанного на базе LLM (Large Language Models), и, следовательно, его корректности. Это достигается путем прогнозирования вероятности успешного выполнения навыков, изученных роботом и упорядоченных в соответствии с планом задачи
Text2Motion является гибридным алгоритмом планирования, который объединяет преимущества планирования на основе shooting и планирования на основе жадного поиска. В случае неудачи планирования на основе shooting , Text2Motion переключается на один шаг жадного поиска. Этот процесс повторяется до тех пор, пока не будет найден план, который может быть успешно выполнен, или не будет достигнут максимальный уровень поиска",,,
CoPAL: Corrective Planning of Robot Actions with Large Language Models,[2310.07263] CoPAL: Corrective Planning of Robot Actions with Large Language Models (arxiv.org),GPT-4,Тест проводился на датасете из работы https://arxiv.org/abs/2304.11477,"План проходит преобразование от высокоуровневой инструкци до низкоуровневой.
План по итогу будет иметь одну из форм:
get <object1> from <object2>
(<hand>)
put <object1> <object2>
pour <object1> <object2> <x [ml]>
open_door <object1>
close_door <object1>
screw <object1>
unscrew <object1>
finger_push <object1> 
wait <x [s]>","Executavility,SR","Обратная связь включает логические ошибки, физические ошибки и ошибки времени выполнения","Авторы предлагают многоуровневую архитектуру планирования, включающую высокоуровневое планирование, среднего уровня и низкого уровня. Каждый уровень отвечает за различные аспекты планирования и верификации, что позволяет эффективно решать сложные задачи планирования для роботов.",,,https://github.com/HRI-EU/Loom/blob/main/data/Travi%20reprompting%20from%20Alex.txt
"On the Self-Verification Limitations of Large
Language Models on Reasoning and Planning Tasks",https://arxiv.org/pdf/2402.08115.pdf,GPT-4,"Game of 24, Graph Coloring, STRIPS planning",,Accuracy,,"Основной вклад статьи заключается в исследовании способности модели GPT-4 к самокритике и обратной связи в рамках трех различных задач: игры в 24, раскраски графов и планирования STRIPS.",,,
Verifiably Following Complex Robot Instructions with Foundation Models,https://arxiv.org/pdf/2402.11498.pdf,"В тексте упоминаются такие LLM как GPT4, Gemini, Llama, и Mistral 7B, которые могут использоваться для перевода из NL в LTL в рамках модуля языковых инструкций. Конкретная модель, которая использовалась в этом случае, не указана. Авторы статьи описывают, что их подход агностичен к конкретной реализации этих моделей,","Два датасета:
1.Первый использут для заполнения шаблона промпта(промпт отвечает за перевод из NL to LTL)(используют датачет для этого из https://arxiv.org/pdf/2303.08006.pdf
2.В качестве датасета для теста используются релевантные для окружения робота инструкции.Находятся в Appendix.3
Пример инструкций:

Go to the red sofa but dont pass by any door then go to the computer, the sofa is behind
the pillar and on the right side

Find the door with posters in front of the yellow pillar then go stand by the tree but
avoid any sofa",,Accuracy,"Expressing instructions as linear temporal logic specifications allows us to verify the correctness of generated plans. However, instead of secondary explicit verification via approaches such as model checking, our approach follows conventional wisdom [https://www.researchgate.net/publication/2673900_An_Automata-Theoretic_Approach_to_Linear_Temporal_Logic] and directly uses specifications to synthesize plans that are correct-by-construction [https://arxiv.org/abs/2103.14464, https://www.researchgate.net/publication/321816144_Synthesis_of_correct-by-construction_behavior_trees].","Рассматривается ряд проблем,связанных с пониманием и выполнением сложных инструкций на естественном языке роботами в неструктурированных средах, алгоритм LIMP предложенный в данной статье решает ряд проблем:
1)Понимание сложных естественных языковых инструкций
2)Понимание и интерпретация пространственных ориентиров и ограничений
3)Навигация и мобильная манипуляция в неструктурированных средах
4)Проверка корректности выполнения инструкций(в статье предполагается, что верифицируется план пользователем)","Noteably, unlike previous work, we do not assume access
to a semantic map with the locations of objects or predicates prespecified. Instead, we assume access to two types
of foundation models: firstly a task-agnostic visual language
model σ that given an image and natural language string
provides a bounding box/segmentation of the image based on
the description, along with a scalar-value score of how well
the description describes the segmentation (e.g: OwL-ViT [49],
ViLD [50], CLIPSeg [51], SAM [52], SEEM [53]). Secondly,
we assume access to an auto-regressive large language model
ψ (e.g: GPT4 [54], Gemini [55], Llama [56], Mistral 7B [57]),
which can be used to sample likely natural language tokens
as a function of a history of tokens. ",,
Translating natural language commands to temporal robot task specification,https://arxiv.org/pdf/2302.11649v1.pdf,GPT series models and the T5-Base model,Собрали свой датасет - https://drive.google.com/drive/folders/1ept4vnvlUevzqUellFt938vV2VDcgdwb,"Input command: 
Go to bookshelf, then workstation A, then go to counter, then back to workstation A.
 
LTL Formula:
F(bookshelf ∧ F(deska ∧ F(kitchen counter ∧ Fdeska)))",Accuracy,-,"Основная ценность данной работы заключается в предложении модульного подхода к переводу естественного языка на спецификации задач линейной временной логики (LTL) для робототехнических систем в контексте навигационных задач. Этот подход предлагает решение следующих задач:

Распознавание референтных выражений RER: Задача состоит в выделении из высказывания номинативных фраз, которые относятся к отдельным объектам в окружающей среде. Это позволяет определить, на что конкретно ссылаются в высказывании. Например, в предложении ""Иди в кафе на улице Мейн, затем в банк, а потом в Макдоналдс"", референтными выражениями будут ""кафе на улице Мейн"", ""банк"" и ""Макдоналдс"".

Привязка референтных выражений к семантической информации о среде (Referring Expression Grounding): Задача состоит в том, чтобы каждому референтному выражению сопоставить идентификатор объекта из набора предопределенных позиций в среде (например, местоположения на карте) и сопоставить его с заранее известными понятиями. Это позволяет привязать естественные выражения к конкретным объектам в среде.

Символьный перевод (Symbolic Translation): Задача состоит в том, чтобы преобразовать естественные выражения в формальные символьные представления, например, LTL формулы. Это включает в себя перевод выражений в набор символов и операторов LTL, а также описание логики последовательности действий. Например, перевод выражения ""Иди в A, затем в B"" в LTL формулу ""F(A ∧ F B)"".","В работе исследуются и сравниваются различные модели для генерации символьных представлений LTL формул на основе NL.
Использовали классические модели на основе Seq2Seq трансформеров, так и  предварительно обученные модели типа GPT-3.",,
Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents,2309.09919.pdf (arxiv.org),GPT 4,Virtualhome,"План задачи описывается на естественном языке,
После этого план переводится в LTL, затем план анализируется и верифицируется и после может быть возвращен обратно на естественный язык

",Safety rate,,"Основная проблема, которую решает статья, является обеспечение безопасности при использовании систем с естественным языком (LLM), которые могут использоваться в качестве агентов для управления роботами.

Главные вопросы, решаемые в статье:

1.Разработка метода обеспечения безопасности для систем понимания естественного языка, работающих в промышленной среде.
2.Создание ""чипа безопасности"", который обеспечивает проверяемые гарантии безопасности, даже если исходная система понимания языка не имеет таких гарантий.
3.Разработка стратегии rteprompting, которая позволяет системам LLM перепланировать действия для предотвращения нарушения безопасности.

Основные вклады статьи:

1.Предложен метод обеспечения безопасности для систем понимания естественного языка с использованием ""чипа безопасности"", который включает в себя формализацию безопасных ограничений, их проверку и применение к исходной системе LLM.
2/Разработана стратегия переподталкивания, которая позволяет системам LLM исправлять планы действий для соблюдения безопасности.
3.Введена система запросов, которая обеспечивает обратную связь агенту LLM о причинах нарушения безопасности и помогает в переподталкивании.","данный подход представляет собой метод верификации плана, который обеспечивает безопасность и соответствие ограничениям",,
AutoTAMP,2306.06531.pdf (arxiv.org),GPT-4,"(Все среды 2D)HouseWorld and Chip’s Challenge are single-agent scenarios. Overcooked, Rover, and Wall are multi-agent scenarios.","Используется LLM для перевода естественного языка в формализованные выражения временной логики (STL), после чего строится траектория с использованием формального планировщика",TASK SUCCESS ,"Любые ошибки предоставляются в качестве обратной связи при повторном запросе модели для создания исправленного STL. Процесс повторяется до тех пор, пока ошибки не будут исправлены (до пяти итераций)","Планирование движения с использованием LLM (LLM End-to-end Motion Planning):
Статья предлагает использовать LLM для напрямую генерации траектории на основе инструкций на естественном языке. Однако возникают проблемы с нарушением ограничений траектории из-за ограниченных пространственных и числовых рассуждений LLM. В статье представлен метод повторного предложения (re-prompting), позволяющий модели генерировать новые траектории при нарушении ограничений.

Планирование задач с использованием LLM (LLM Task Planning):
Статья также рассматривает использование LLM для генерации последовательности подзадач на основе инструкций на естественном языке. Подзадачи затем передаются независимому планировщику движения. Статья сравнивает несколько методов, включая наивное планирование задач, метод SayCan и метод LLM Task Planning + Feedback, который включает проверку выполнимости подзадач и возможность повторного предложения для исправления ошибок.

Трансляция и проверка спецификации LLM с обратной связью (Autoregressive LLM Specification Translation & Checking):
В этом подходе предлагается использовать LLM для перевода естественноязыковых инструкций в формальные выражения на языке временной логики сигналов (STL), а затем планировать траекторию с использованием STL-планировщика. Для улучшения производительности перевода и проверки предлагаются техники повторного предложения для исправления синтаксических и семантических ошибок.","Синтаксическая проверка и семантическая проверка:
Синтаксическая проверка: Поскольку открытое преобразование может страдать от синтаксических ошибок, вводятся методы проверки синтаксиса. Используется верификатор для проверки синтаксических ошибок (применяется простой проверчик синтаксиса STL на основе правил); любые ошибки предоставляются в качестве обратной связи при повторном запросе модели для создания исправленного STL. Процесс повторяется до тех пор, пока ошибки не будут исправлены (до пяти итераций).

Семантическая проверка: Для семантических ошибок предлагается новый авторегрессивный метод повторного запроса; в качестве контекста ряд состояний, сгенерированных планировщиком STL (например, [[в(дорога), 0], [в(красная кухня), 0.5], [в(синяя ванная2), 1.2], ...]), предоставляется вместе с исходной инструкцией, и LLM запрашивается, чтобы проверить, соответствует ли план семантике инструкции. Если это не так, LLM запрашивается для изменения STL, что приводит к повторному запросу синтаксической и семантической проверок. Этот процесс завершается в случае отсутствия обнаруженных ошибок или отсутствия изменений в STL (до трех итераций).",,
Cook2LTL,https://arxiv.org/abs/2310.00163,"NER - BERT,
Another parts - GPT4","Датасет - обычные рецепты, среда AI2Thor",Подается последовательность шагов на NL затем переводится в LTL,Executability,-,"Статья представляет систему Cook2LTL, которая переводит рецепты в LTL, все рецепты построены на манипуляциях с объектами

Модульная архитектура:
1) Semantically parses r
into a function representation a
for every detected high-level action.
2) Reduces each high-level action a ∈ A/ to a combination
of primitive actions from A.
3) Caches the action reduction policy for future use,
thereby gradually building an action library that consists of parametric functions that express high-level
cooking actions in the form of primitive actions.
4) Translates r
into an LTL formula ϕ with function
representations as atomic propositions.
","Работает на рецептах по приготовлению пищи, может быть интересно встроит в планировщик, который работает в интерактивной среде, посмотреть как справляется",,
Lang2LTL,https://arxiv.org/abs/2302.11649,"Finetuned LLM: T5-Base

Prompt LLM:  GPT-3 and GPT-4 

Seq2Seq Transformers: trained an encoder-decoder model",Датасет в основном состоит из навигационных задач,,,-,"Lang2LTL система модульная как Cook2LTL:

Распознавание выражений (RER): 
Этот этап выделяет подстроки в команде пользователя, которые относятся к утверждениям о мире, например, названиям объектов или мест. Система использует адаптированные модели GPT-4 для достижения высокой производительности в этом задании.

Привязка выражений (REG):
 Этот этап ассоциирует распознанные выражения с конкретными утверждениями о мире, используя векторные представления (эмбеддинги) для измерения сходства между распознанными выражениями и предложениями о мире.

Lifted Translation:
Этот этап переводит поднятое выражение (символическое представление) в LTL формулы. Такой подход сокращает размер словаря и позволяет использовать данные из различных областей для обучения модели.","В отличие от Cook2LTL есть модуль привязки к среде, т.е можно импортировать в разные среды",,
Obtaining Hierarchy from Human Instructions: an LLMs-based Approach,https://openreview.net/pdf?id=sy9YuA8GzY,,,,,,,,,
Decomposition-based Hierarchical Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications,https://arxiv.org/pdf/2308.10393.pdf,,,,,,,,,
Conformal Temporal Logic Planning using Large Language Models,https://arxiv.org/pdf/2309.10092.pdf,,,,,,,,,
Unifying Large Language Models and Knowledge Graphs: A Roadmap,https://arxiv.org/pdf/2306.08302.pdf,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
Errors are Useful Prompts: Instruction Guided Task Programming with Verifier-Assisted Iterative Prompting,2303.14100.pdf (arxiv.org),,,,,,,,,
calable Multi-Robot Collaboration with Large Language Models: Centralized or Decentralized Systems?,2309.15943.pdf (arxiv.org),,,,,,,,,
On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS),[2401.02500] On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS) (arxiv.org),,,,,,,,,https://github.com/GuanSuns/LLMs-World-Models-for-Planning
RoCo: Dialectic Multi-Robot Collaboration with Large Language Models,https://arxiv.org/pdf/2307.04738.pdf,,,,,,,,,GitHub - HRI-EU/Loom
Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning,2305.14909.pdf (arxiv.org),,,,,,,,,
Chain-of-Verification Reduces Hallucination in Large Language Models,[2309.11495] Chain-of-Verification Reduces Hallucination in Large Language Models (arxiv.org),,,,,,,,,
Real-World Planning with PDDL+ and Beyond,https://arxiv.org/pdf/2402.11901.pdf,,,,,,,,,https://github.com/h2r/Lang2LTL
TALplanner: An Empirical Investigation of a Temporal Logic-based Forward Chaining Planner,https://www.ida.liu.se/~jonkv82/papers/time99.pdf,,,,,,,,,